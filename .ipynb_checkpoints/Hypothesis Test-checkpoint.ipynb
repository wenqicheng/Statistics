{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 2: Hypothesis Test\n",
    "Is there strong evidence that the population mean $\\mu$ is differenet from some value that is of interest to us.\n",
    "Is it different from some hypothesized value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis is $H_0: \\mu = \\mu_0$  \n",
    "possible alternatives hypothesis: \n",
    "- $H_a: \\mu < \\mu_0$ (one-sided/tailed test)\n",
    "- $H_a: \\mu > \\mu_0$ (one-sided/tailed)\n",
    "- $H_a: \\mu \\neq \\mu_0$ (two-sided/tailed)\n",
    "\n",
    "\n",
    "There are two scenarios:\n",
    "- $\\sigma$ is known, Z-test\n",
    "- $\\sigma$ is unknown, T-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Z-test & T-test\n",
    "\n",
    "_suppose we have a simple random sample of n observations from a normally distributed population where $\\sigma$ is known. The normality assumption, that we are sampling from a normally distributed populaiton is very important when the sample size is small. But as the sample size goes bigger and bigger, it is less and less important due to the centrel limit theorem._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test $H_0: \\mu = \\mu_0$, we can sample from the populaiton: sample size n, sample mean $\\bar{X}$)\n",
    "\n",
    "Because of the centrel limit theorem: $$ \\bar{X} \\sim N(\\mu, \\frac{\\sigma^2}{n}) $$ \n",
    "\n",
    "#### Case 1:if we know the population standard deviation, then we can use the Z-test:\n",
    "$$Zscore = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}} \\sim N(0, 1) $$\n",
    "\n",
    "#### Case 2: if we don't know the population standard deviation, then we can use the T statistic:\n",
    "\\begin{equation}\n",
    "Tscore = \\frac{\\bar{X} - \\mu_0}{\\sigma_\\bar{X}} = \\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}} \\sim T(n-1\\ degree\\ of\\ freedom)\\\\\n",
    "where:\\ \\sigma_\\bar{X} = \\frac{s}{\\sqrt{n}}\\ and\\ s = \\sqrt{\\frac{\\Sigma(x_i - \\bar{x})^2}{n - 1}} \n",
    "\\end{equation}\n",
    "Note:\n",
    "- we use sample standard deviation(s) to estimate population standard deviation $\\sigma$. We use $\\frac{s}{\\sqrt{n}}$, which called standard error of $\\bar{X}$, to eastimate the standard deviation($\\frac{\\sigma}{\\sqrt{n}}$) of the sampling distribution of the sample mean.\n",
    "- T distribution is very similar to standard normal distribution except lower peak and heavier tails. As the degree of freedom increase, the T distribution tends toward the standard normal distribution, because the standard error estimates the standard deviation better and better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rejection Region Approach\n",
    "1. choose a value for $\\alpha$, the significance level of the test.  \n",
    "$\\alpha$ is the probability of rejecting the null hypothesis if it is true\n",
    "2. Find the appropriate rejectoin region.\n",
    "3. Reject the null hypothesis if the test statistic falls in the rejection region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. P-value  \n",
    "The p-value measure how strength of the evidence against the null hypothesis.\n",
    "\n",
    "__The definition__:  \n",
    "the p-value is the probability of getting the ovserved value of the test statistic, or a vlaue with even greater evidence against null hypothesis, if the null hypothesis is true.  \n",
    "\n",
    "- The smaller the p-value, the greater the evidence against the null hypothesis.  \n",
    "- If we have a given significance level $\\alpha$, then: reject $H_0$ if p-value <= $\\alpha$.  \n",
    "(if p-value <= $\\alpha$, the evidence against $H_0$ is significant at the $\\alpha$ level of significance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Type I errors, Type II errors, Power of the Test.\n",
    "\n",
    "- A Type I error is rejecting $H_0$ when, in reality, it is true.  \n",
    "P(Tytpe I error|$H_0$ is true) = $\\alpha$  \n",
    "- A Type II error is failing to reject $H_0$ when, in reality, it is false.  \n",
    "P(Tytpe II error|$H_0$ is false) = $\\beta$  \n",
    "$\\beta$ depends on a number of factors, including the choice of $\\alpha$, the sample size, and the true value of the parameter  \n",
    "- Power is the probability of rejecting the null hypothesis, given it is false  \n",
    "Power = 1 - P(Type II error) = 1 - $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   ||               __Underlying reality__(unknown)|\n",
    "|----|------------|----------------|----------------|\n",
    "|    |            |$H_0$ is false  |$H_0$ is true   |\n",
    "|__conclusion from test__(known)|reject $H_0$|correct decision|Type I error|\n",
    "|    |Accept $H_0$|Type II error   |correct decision|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we choose a very small $\\alpha$, we will be making it very hard to reject the $H_0$. Then we will have a small chance to make a Type I error, but we have a very high chance to make a Type II error. The Power of the test is high.\n",
    "\n",
    "If we choose a larger value of $\\alpha$, it will be vice versa. The Power of the test is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||||Relationship between parameters|\n",
    "|-|-|-|-|-|-|\n",
    "|$\\alpha$ up|P(reject) up|P(Type I) up|P(Type II) down|$\\beta$ down|Power up|\n",
    "|$\\alpha$ down|P(reject) down|P(Type I) down|P(Type II) up|$\\beta$ up|Power down|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Confident Interval\n",
    "A 95% confidence interval is a range of values that you can be 95% certain contains the true mean of the population. This is not the same as a range that contains 95% of the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-teste: we would reject $H_0$ at $\\alpha$ = 0.05, if\n",
    "$$\n",
    " \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}} <= -1.96\\ or\\ \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}} >= 1.96\n",
    "$$\n",
    "isolating $\\mu_0$, we would reject $H_0$:\n",
    "$$\n",
    "\\mu_0 >= \\bar{X} + 1.96*\\frac{\\sigma}{\\sqrt{n}}\\ or\\ \\mu_0 <= \\bar{X} - 1.96*\\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "- The upper bound of the 95% confidence interval is $\\bar{X} + 1.96*\\frac{\\sigma}{\\sqrt{n}}$  \n",
    "- The lower bound of the 95% confidence interval is $\\bar{X} - 1.96*\\frac{\\sigma}{\\sqrt{n}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Distribution of P-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: $\\mu$ = 0  \n",
    "$H_a$: $\\mu$ > 0  \n",
    "where population_sigma = 1.\n",
    "\n",
    "I am testing 3 scenarios.\n",
    "- The population mean is 0, which means $H_0$ is ture\n",
    "- The population mean is 1, which means $H_0$ is false\n",
    "- The populaiton mean is 2, which means $H_0$ is false  \n",
    "\n",
    "I picked up 1000 samples from each scenario with sample size 50. After calculating the P-value of each sample, we can histgram the distribution of P-value for each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "num_sample = 10000\n",
    "\n",
    "for i in range(0, num_sample):\n",
    "    # population_1\n",
    "    mu1, sigma1 = 0, 1\n",
    "    sample1 = np.random.normal(mu1, sigma1, sample_size)\n",
    "    \n",
    "    \n",
    "\n",
    "    # population_2\n",
    "    mu2, sigma2 = 1, 1\n",
    "    sample1 = np.random.normal(mu2, sigma2, sample_size)\n",
    "\n",
    "    # population_3\n",
    "    mu3, sigma3 = 2, 1\n",
    "    sample1 = np.random.normal(mu3, sigma3, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44128516, -0.60979832, -0.34385109,  1.30108423, -0.71732452,\n",
       "       -1.91477831, -0.21408047,  1.27536415,  1.06191106, -1.24144945,\n",
       "       -0.76279453, -1.0733659 ,  0.40119336,  0.53604004,  1.1890227 ,\n",
       "       -1.91696102, -1.64305129, -0.4724886 , -0.98144517,  0.75864234])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = np.random.normal(mu1, sigma1, sample_size1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Two Means Test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1: \n",
    "- independent simple random samples.\n",
    "- Normally distributed populations.(not very important for large sample sizes.\n",
    "- $\\sigma_1$ and $\\sigma_2$ are known.\n",
    "\n",
    "\n",
    "The sample mean distribution of $\\bar{X_1} - \\bar{X_2}$:\n",
    "- Has a mean of $\\mu_1 - \\mu_2$\n",
    "- Has a standard deviation of $\\sigma_{\\bar{X_1} - \\bar{X_2}} = \\sqrt{\\frac{\\sigma_1^2}{n1} + \\frac{\\sigma_2^2}{n2}}$\n",
    "- Is normally distributed\n",
    "\n",
    "\n",
    "We want to test $H_0$: $\\mu1 = \\mu2$\n",
    "\\begin{equation}\n",
    "Zscore = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{\\sigma_1^2}{n1} + \\frac{\\sigma_2^2}{n2}}} \\sim N(0,1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If we don't feel comfortable assuming normality, there are other options:\n",
    "- Mann-Whitney U.(Also known as the Wicoxon rank-sum test)\n",
    "- Bootstrap methods and permutaiton tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2(pooled variance T-test):\n",
    "- everything is the same as case 1 except we don't know $\\sigma_1$ and $\\sigma_2$\n",
    "- equal population variances($\\sigma_1^2 = \\sigma_2^2 = \\sigma^2$)\n",
    "\n",
    "Step 1:  Estimate the common populaiton variance $\\sigma^2$ with the pooled sample variance  \n",
    "        $s_p^2 = \\frac{(n_1 -1)s_1^2 + (n_2 -1)s_2^2}{n_1+n_2-2}$  \n",
    "Step 2: Estimate the standard error of the difference in sample means:  \n",
    "        $SE(\\bar{X_1} - \\bar{X_2}) = s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}$  \n",
    "SE estimates the true standard deviation of the sampling distribution of the difference in sample means  \n",
    "Step 3: $\\bar{X_1} - \\bar{X_2} \\sim T(n1+n2-2\\ degrees\\ of freedom)$  \n",
    "Step 4: A(1-$\\alpha$)\\*100% confident interval for $\\mu_1 - \\mu_2$ is __Estimator + margin of Error__  \n",
    "$\\bar{X_1} - \\bar{X_2} \\pm t_{\\alpha/2} * SE(\\bar{X_1} - \\bar{X_2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "- it is an exact procedure\n",
    "- it is consistent with other commen statistical procedure. It means the conclusion will be the same if we use pooled\n",
    "\n",
    "Disadvantages:\n",
    "- additional assumptions.\n",
    "- perform very poorly for some violations of the equal virance assumption\n",
    "- the problem is worse if the sample sizes are very different, from which large sample sizes do not save us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 3(unpooled variance T-test, Welch T-test):\n",
    "- everything is the same as case 1 except we don't know $\\sigma_1$ and $\\sigma_2$, and they are not equal\n",
    "- Welch procedure is an approximate(not exact) procedure.\n",
    "\n",
    "Step 1: Calculate the standard error of the difference in smaple means:\n",
    "$SE_W(\\bar{X_1} - \\bar{X_2}) = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}$  \n",
    "\n",
    "$\\bar{X_1} - \\bar{X_2} \\pm t_{\\alpha/2} * SE_W(\\bar{X_1} - \\bar{X_2})$\n",
    "\n",
    "Welch-Satterthwaite approximation to the degrees of freedom:  \n",
    "$df = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2}{\\frac{1}{n_1-1}(\\frac{s_1^2}{n_1})^2 + \\frac{1}{n_2-1}(\\frac{s_2^2}{n_2})^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "- no require the assumption of equal population variances\n",
    "- It works better than the pooled-variance t in many situations  \n",
    "\n",
    "Disadvantages:\n",
    "- only an approximate(not exact procedure)\n",
    "- degree of freedom is a little complicated\n",
    "- not consistent with other commen statistical techniques, like regression and ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Paired Difference t Procedure\n",
    "When we take two measurements on the same individual or we take two measurements on a paired of people, like Twins, the samples are not independent, but dependent and paired. So we can't use the pooled variance T procedure. What we can do is calculate the difference between the paired groups and do a paired difference T procedure.  \n",
    "\n",
    "Assumption:\n",
    "- The sample differences are a simple random sample from the population of differences.\n",
    "- The population of differences is normally distributed.\n",
    "\n",
    "After we got the sample difference, it becomes a normal T procedure.  \n",
    "$\\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}} \\sim T(n-1\\ degree\\ of\\ freedom)$\n",
    "\n",
    "Note: if we don't feel it is reasonable to assume normality, we can use a nonparametric(distirbution-free) procedure.(e.g. Sign test, signed-rank test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
